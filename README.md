
# ðŸŒ«ï¸ DehazeFlow: Style-Aware Dehazing with Attention

This repository implements a **style transfer-based image dehazing** model using **Glow-style invertible networks**, **adaptive instance normalization (AdaIN)**, and **attention mechanisms** (spatial, channel, or hybrid). It supports both reference-based and reference-free dehazing with flexible encoder and loss designs.

---

## ðŸ”§ Features
- âœ¨ Style-aware image restoration using style transfer
- ðŸŒˆ Glow-based generative architecture
- ðŸŽ¯ Attention-enhanced style injection (spatial, channel, CBAM)
- ðŸŽ¨ Supports VGG-based and learned style encoders
- ðŸ§  Perceptual + reconstruction losses
- ðŸ“ˆ Logging, checkpointing, and attention map visualization

---

## ðŸ“ Project Structure

```
.
â”œâ”€â”€ train.py                     # Entry point to train the model
â”œâ”€â”€ config
â”‚   â”œâ”€â”€ config.yaml              # Editable config file for job settings
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ network/
â”‚   â”‚   â”œâ”€â”€ net.py               # Style and content encoder
â”‚   â”‚   â”œâ”€â”€ glow.py              # Main Glow model
â”‚   â”‚   â”œâ”€â”€ attention.py         # Optional attention layers
â”‚   â”œâ”€â”€ trainers/
â”‚   â”‚   â””â”€â”€ Trainer.py           # Training logic
â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â””â”€â”€ tv_loss.py           # TV and perceptual loss
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ utils.py             # Scheduler, seed setup, etc.
â”œâ”€â”€ data/                        # Input image directory
â”‚   â”œâ”€â”€ trainA/                  # Hazy images
â”‚   â””â”€â”€ trainB/                  # Clear style/reference images
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ model_save/              # Saved checkpoints
â”‚   â”œâ”€â”€ img_save/                # Training visual logs
â”‚   â””â”€â”€ test_save/               # Inference results
```

---

## ðŸš€ Quick Start

### 1. Setup Environment
```bash
conda create -n dehazeflow python=3.9
conda activate dehazeflow
pip install -r requirements.txt
```

### 2. Prepare Dataset
Ensure your dataset folder follows this structure:
```
dataset/
â”œâ”€â”€ trainA/   # hazy input images
â”œâ”€â”€ trainB/   # clear reference images
```

### 3. Edit Config
Edit the file `config.yaml` to match your training preferences:
```yaml
job_name: dehazeflow_v1
lr: 1e-4
n_flow: 8
n_block: 3
z_dim: 1920
content_weight: 1.0
style_weight: 10.0
recon_weight: 1.0
use_attention: true
keep_ratio: 1.0
```

### 4. Train the Model
```bash
python train.py
```

---

## ðŸ§ª Inference
During inference, you can provide a hazy image and a reference clear image (if enabled), or use a fixed style code (for reference-free mode).

---

## ðŸ“ Citation
If you use this work in your research or publication, please cite your thesis and include:

> *"Style-Aware Dehazing via Glow-based Style Transfer with Attention Modulation" â€“ [Alfin Nurhalim], [Institut Teknologi Bandung], 2025*
